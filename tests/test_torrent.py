import asyncio
import concurrent.futures
import filecmp
import logging
import os
import shutil
import tempfile
import unittest.mock

from unittest import TestCase
from typing import List

from pyto.bencoding import bdecode, bencode
from pyto.torrent import Torrent, init, download, metainfo, _validate_structure

TEST_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
# DATA_DIR is TEST_FILE_DIR/data
DATA_DIR = os.path.join(TEST_FILE_DIR, 'data')


class TestMetainfo(unittest.TestCase):
    def test_validate_structure(self):
        """Test the _validate_structure function"""
        # Call _validate_structure with twice the same object: it should always return True
        success_test_cases = [
            {'string': 'http://example.com/announce', 'int': 42, 'list': [1, 2]},
            {'dict': {'list': [1, 2, 3], 'int': 1}, 'str': 'str'},
        ]

        for test in success_test_cases:
            with self.subTest(test=test):
                self.assertTrue(_validate_structure(test, test))

        # Dictionaries in 'data' are allowed to have keys missing from the schema
        self.assertTrue(_validate_structure({'unused': 0, 'used': 1}, {'used': 1}))

        # Diverging data structures
        failure_test_cases = [
            ({'present': 0}, {'present': 0, 'missing': 1}),
            ([1, 2, 'string not int'], [1, 2, 3])
        ]

        for data, schema in failure_test_cases:
            with self.subTest(data=data, schema=schema):
                self.assertFalse(_validate_structure(data, schema))


    def test_metainfo(self):
        """Test the metainfo function by comparing its output to torrent generated by other
        software"""

        # List directories in DATA_DIR/files which will be used for this test. Matching torrent
        # files generated by another software must be found in DATA_DIR/torrent files/
        test_cases = ['single_file', 'multiple_files']

        for directory in test_cases:
            dirpath = os.path.join(DATA_DIR, 'files', directory)
            torrent_file = os.path.join(DATA_DIR, 'torrent_files', directory + '.torrent')

            with self.subTest(directory=directory):
                with open(torrent_file, "rb") as f:
                    m_target = bdecode(f.read())

                piece_length = m_target[b'info'][b'piece length']
                m_computed = metainfo(dirpath, piece_length, 'http://example.com:8080/announce')

                if b'files' in m_target[b'info']:
                    info_keys = [b'files']
                else:
                    info_keys = [b'length']
                info_keys += [b'pieces']

                for key in info_keys:
                    self.assertEqual(m_computed[b'info'][key], m_target[b'info'][key])


class TestTorrentCreation(unittest.TestCase):
    def test_from_file(self):
        torrent_dir = os.path.join(DATA_DIR, "torrent_files")
        for file in os.listdir(torrent_dir):
            filename = os.path.join(torrent_dir, os.fsdecode(file))
            with self.subTest(filename=filename):
                Torrent.from_file(filename)


# TODO: Eventually this should be replaced by a TorrentManager class that allows the same Torrent
# (same infohash) to be downloaded simultaneously multiple times. This would only be useful
# from a testing perspective. From a user perspective you want a single Torrent instance
# by infohash (which might be updated with new trackers or peers if the Torrent is added to
# the TorrentManager from multiple sources).
def two_peer_swarm(data_dir, seeder_port=6881, leecher_port=6882):
    # Setup asyncio loop
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.set_debug(False)
    executor = concurrent.futures.ThreadPoolExecutor()
    loop.set_default_executor(executor)

    # Setup working directories
    tmp_dir = tempfile.mkdtemp()
    seeder_dir = os.path.join(tmp_dir, "seeder")
    leecher_dir = os.path.join(tmp_dir, "leecher")
    # The seeder's directory is initiated with all the files
    shutil.copytree(data_dir, seeder_dir)
    # The leecher's directory is empty
    os.makedirs(leecher_dir, exist_ok=True)

    # Create on the fly metainfo file on disk
    torrent_file = os.path.join(tmp_dir, 'metainfo.torrent')
    m = metainfo(data_dir, 32768, 'http://www.example.com/announce')
    with open(torrent_file, 'wb') as f:
        f.write(bencode(m))

    # Start both torrents
    torrent_seeder = loop.run_until_complete(init(torrent_file, seeder_dir))
    torrent_leecher = loop.run_until_complete(init(torrent_file, leecher_dir))

    async def seeder():
        with unittest.mock.patch.object(Torrent, 'get_peers') as get_peers_mocked:
            # Mock Torrent.get_peers to return an empty list
            get_peers_mocked.return_value = []
            await download(torrent_seeder, seeder_port)

    async def leecher():
        with unittest.mock.patch.object(Torrent, 'get_peers') as get_peers_mocked:
            # Mock Torrent.get_peers to return the address of the seeder
            get_peers_mocked.return_value = [("127.0.0.1", seeder_port)]
            await download(torrent_leecher, leecher_port)

    async def wait_for(torrent: Torrent, events: List[str]):
        event = None
        while event not in events:
            event = await torrent.queue.get()
        return event

    # Futures
    f_seeder = asyncio.ensure_future(seeder())
    f_wait_accept_conns = asyncio.ensure_future(
        wait_for(torrent_seeder, ["EVENT_ACCEPT_CONNECTIONS", "EVENT_END"])
    )
    f_download_complete = None

    futures = {f_seeder, f_wait_accept_conns}
    while futures:
        done, futures = loop.run_until_complete(
            asyncio.wait(futures, return_when=asyncio.FIRST_COMPLETED)
        )

        for item in done:
            result = item.result()

            # Once the seeder accepts connection, start the leecher and wait for it to complete
            # the download
            if item == f_wait_accept_conns:
                if result == "EVENT_ACCEPT_CONNECTIONS":
                    f_leecher = asyncio.ensure_future(leecher(), loop=loop)
                    f_download_complete = asyncio.ensure_future(
                        wait_for(torrent_leecher, ["EVENT_DOWNLOAD_COMPLETE", "EVENT_END"])
                    )
                    futures = futures | {f_leecher, f_download_complete}
                elif result == "EVENT_END":
                    print("leecher failed")

            # Once the leecher has downloaded the file, stop all torrents
            if item == f_download_complete:
                if result == "EVENT_DOWNLOAD_COMPLETE":
                    loop.run_until_complete(torrent_leecher.stop())
                    loop.run_until_complete(torrent_seeder.stop())
                elif result == "EVENT_END":
                    print("seeder failed")

    loop.stop()
    loop.close()

    assert filecmp.dircmp(seeder_dir, data_dir)
    assert filecmp.dircmp(leecher_dir, data_dir)
    shutil.rmtree(tmp_dir)


class EndToEnd(TestCase):
    """End to end tests"""
    def test_self(self):
        """Test the download of files from another instance of PyTo"""
        logging.basicConfig(
            level=logging.DEBUG,
            format="[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s",
            datefmt="%H:%M:%S")

        test_cases_dir = os.path.join(DATA_DIR, "files")
        for d in os.listdir(test_cases_dir):
            if os.path.isdir(os.path.join(test_cases_dir, d)):
                full_directory_path = os.path.join(test_cases_dir, d)
                with self.subTest(directory=full_directory_path):
                    two_peer_swarm(full_directory_path)


if __name__ == '__main__':
        unittest.main()
